{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a4c6eac7",
   "metadata": {},
   "source": [
    "\n",
    "#  Rossmann Store Sales Prediction using Gradient Boosting (XGBoost)\n",
    "\n",
    "This project applies a complete machine learning workflow to the **Rossmann Store Sales** dataset.\n",
    "\n",
    "The notebook includes:\n",
    "- Exploratory Data Analysis (EDA)\n",
    "- Domain-driven feature engineering\n",
    "- Proper use of PCA for analysis and dimensionality understanding\n",
    "- Gradient Boosting with XGBoost\n",
    "- K-Fold Cross Validation\n",
    "- Hyperparameter tuning\n",
    "- Feature importance interpretation\n",
    "- Final prediction and submission generation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "809d2c95",
   "metadata": {},
   "source": [
    "## Library Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f87c4cb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler, OneHotEncoder, StandardScaler\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "pd.set_option(\"display.max_columns\", 120)\n",
    "sns.set(style=\"whitegrid\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95157dea",
   "metadata": {},
   "source": [
    "## Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a2db3f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "ross_df = pd.read_csv(\"./rossmann-store-sales/train.csv\", low_memory=False)\n",
    "store_df = pd.read_csv(\"./rossmann-store-sales/store.csv\")\n",
    "test_df  = pd.read_csv(\"./rossmann-store-sales/test.csv\")\n",
    "submission_df = pd.read_csv(\"./rossmann-store-sales/sample_submission.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4727a981",
   "metadata": {},
   "source": [
    "## Data Merging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "637304fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "merged_df = ross_df.merge(store_df, how=\"left\", on=\"Store\")\n",
    "merged_test_df = test_df.merge(store_df, how=\"left\", on=\"Store\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3f334b6",
   "metadata": {},
   "source": [
    "## Exploratory Data Analysis (EDA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03e69b1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt.figure(figsize=(8,4))\n",
    "sns.histplot(merged_df[\"Sales\"], bins=50)\n",
    "plt.title(\"Sales Distribution\")\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(12,8))\n",
    "sns.heatmap(merged_df.select_dtypes(include=np.number).corr(), cmap=\"coolwarm\")\n",
    "plt.title(\"Numerical Feature Correlation\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8e03424",
   "metadata": {},
   "source": [
    "## Date Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "540c26df",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def split_date(df):\n",
    "    df[\"Date\"] = pd.to_datetime(df[\"Date\"])\n",
    "    df[\"Year\"] = df.Date.dt.year\n",
    "    df[\"Month\"] = df.Date.dt.month\n",
    "    df[\"Day\"] = df.Date.dt.day\n",
    "    df[\"WeekOfYear\"] = df.Date.dt.isocalendar().week\n",
    "\n",
    "split_date(merged_df)\n",
    "split_date(merged_test_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb771f2b",
   "metadata": {},
   "source": [
    "## Remove Closed Stores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "017b5844",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "merged_df = merged_df[merged_df.Open == 1].copy()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c87246b9",
   "metadata": {},
   "source": [
    "## Competition Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5b5b248",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def comp_months(df):\n",
    "    df[\"CompetitionOpen\"] = (\n",
    "        12 * (df.Year - df.CompetitionOpenSinceYear) +\n",
    "        (df.Month - df.CompetitionOpenSinceMonth)\n",
    "    )\n",
    "    df[\"CompetitionOpen\"] = df[\"CompetitionOpen\"].map(lambda x: 0 if x < 0 else x).fillna(0)\n",
    "\n",
    "comp_months(merged_df)\n",
    "comp_months(merged_test_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bda8484d",
   "metadata": {},
   "source": [
    "## Promotion Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9fff654",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def check_promo_month(row):\n",
    "    month2str = {1:\"Jan\",2:\"Feb\",3:\"Mar\",4:\"Apr\",5:\"May\",6:\"Jun\",\n",
    "                 7:\"Jul\",8:\"Aug\",9:\"Sept\",10:\"Oct\",11:\"Nov\",12:\"Dec\"}\n",
    "    try:\n",
    "        months = (row[\"PromoInterval\"] or \"\").split(\",\")\n",
    "        return int(row[\"Promo2Open\"] and month2str[row[\"Month\"]] in months)\n",
    "    except:\n",
    "        return 0\n",
    "\n",
    "def promo_cols(df):\n",
    "    df[\"Promo2Open\"] = (\n",
    "        12 * (df.Year - df.Promo2SinceYear) +\n",
    "        (df.WeekOfYear - df.Promo2SinceWeek) * 7 / 30.5\n",
    "    )\n",
    "    df[\"Promo2Open\"] = df[\"Promo2Open\"].map(lambda x: 0 if x < 0 else x).fillna(0) * df[\"Promo2\"]\n",
    "    df[\"IsPromo2Month\"] = df.apply(check_promo_month, axis=1) * df[\"Promo2\"]\n",
    "\n",
    "promo_cols(merged_df)\n",
    "promo_cols(merged_test_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f5e925d",
   "metadata": {},
   "source": [
    "## Input & Target Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aeaa923",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "input_cols = [\n",
    "    \"Store\",\"DayOfWeek\",\"Promo\",\"StateHoliday\",\"SchoolHoliday\",\n",
    "    \"StoreType\",\"Assortment\",\"CompetitionDistance\",\"CompetitionOpen\",\n",
    "    \"Day\",\"Month\",\"Year\",\"WeekOfYear\",\"Promo2\",\"Promo2Open\",\"IsPromo2Month\"\n",
    "]\n",
    "\n",
    "target_col = \"Sales\"\n",
    "\n",
    "inputs = merged_df[input_cols].copy()\n",
    "targets = merged_df[target_col].copy()\n",
    "test_inputs = merged_test_df[input_cols].copy()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af4fc467",
   "metadata": {},
   "source": [
    "## Scaling & Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "439eeaaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "numeric_cols = [\n",
    "    \"Store\",\"Promo\",\"SchoolHoliday\",\"CompetitionDistance\",\n",
    "    \"CompetitionOpen\",\"Promo2\",\"Promo2Open\",\"IsPromo2Month\",\n",
    "    \"Day\",\"Month\",\"Year\",\"WeekOfYear\"\n",
    "]\n",
    "\n",
    "categorical_cols = [\"DayOfWeek\",\"StateHoliday\",\"StoreType\",\"Assortment\"]\n",
    "\n",
    "scaler = MinMaxScaler().fit(inputs[numeric_cols])\n",
    "inputs[numeric_cols] = scaler.transform(inputs[numeric_cols])\n",
    "test_inputs[numeric_cols] = scaler.transform(test_inputs[numeric_cols])\n",
    "\n",
    "encoder = OneHotEncoder(sparse=False, handle_unknown=\"ignore\").fit(inputs[categorical_cols])\n",
    "encoded_cols = list(encoder.get_feature_names_out(categorical_cols))\n",
    "\n",
    "inputs[encoded_cols] = encoder.transform(inputs[categorical_cols])\n",
    "test_inputs[encoded_cols] = encoder.transform(test_inputs[categorical_cols])\n",
    "\n",
    "X = inputs[numeric_cols + encoded_cols]\n",
    "X_test = test_inputs[numeric_cols + encoded_cols]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31f9b5d6",
   "metadata": {},
   "source": [
    "## PCA Analysis (Exploratory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ad312a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "std_scaler = StandardScaler()\n",
    "X_std = std_scaler.fit_transform(X)\n",
    "\n",
    "pca = PCA()\n",
    "X_pca = pca.fit_transform(X_std)\n",
    "\n",
    "plt.figure(figsize=(8,5))\n",
    "plt.plot(np.cumsum(pca.explained_variance_ratio_), marker=\"o\")\n",
    "plt.xlabel(\"Number of Components\")\n",
    "plt.ylabel(\"Cumulative Explained Variance\")\n",
    "plt.title(\"PCA Explained Variance\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14bc21aa",
   "metadata": {},
   "source": [
    "\n",
    "PCA is used here to understand:\n",
    "- Redundancy in engineered features\n",
    "- Variance concentration\n",
    "- Dimensional structure of the dataset\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96cddc27",
   "metadata": {},
   "source": [
    "## Evaluation Metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddfeaf5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def rmse(a, b):\n",
    "    return mean_squared_error(a, b, squared=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99be5c89",
   "metadata": {},
   "source": [
    "## K-Fold Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c22deed9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def train_and_evaluate(X_train, y_train, X_val, y_val, **params):\n",
    "    model = XGBRegressor(random_state=42, n_jobs=-1, **params)\n",
    "    model.fit(X_train, y_train)\n",
    "    return rmse(model.predict(X_val), y_val)\n",
    "\n",
    "kfold = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "for tr, vl in kfold.split(X):\n",
    "    val_rmse = train_and_evaluate(\n",
    "        X.iloc[tr], targets.iloc[tr],\n",
    "        X.iloc[vl], targets.iloc[vl],\n",
    "        max_depth=4, n_estimators=50\n",
    "    )\n",
    "    print(\"Validation RMSE:\", val_rmse)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ae9fa25",
   "metadata": {},
   "source": [
    "## Final Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2f53602",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "final_model = XGBRegressor(\n",
    "    n_estimators=1000,\n",
    "    learning_rate=0.2,\n",
    "    max_depth=10,\n",
    "    subsample=0.9,\n",
    "    colsample_bytree=0.7,\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "final_model.fit(X, targets)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7958ba65",
   "metadata": {},
   "source": [
    "## Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bce6e3e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "importance_df = pd.DataFrame({\n",
    "    \"feature\": X.columns,\n",
    "    \"importance\": final_model.feature_importances_\n",
    "}).sort_values(\"importance\", ascending=False)\n",
    "\n",
    "plt.figure(figsize=(10,6))\n",
    "sns.barplot(data=importance_df.head(15), x=\"importance\", y=\"feature\")\n",
    "plt.title(\"Top Feature Importances\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7d73eb0",
   "metadata": {},
   "source": [
    "## Prediction & Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ce716ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "test_preds = final_model.predict(X_test)\n",
    "submission_df[\"Sales\"] = test_preds * test_df.Open.fillna(1)\n",
    "submission_df.to_csv(\"submission.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f241845",
   "metadata": {},
   "source": [
    "\n",
    "## Project Summary\n",
    "\n",
    "This notebook demonstrates:\n",
    "- Deep EDA and feature understanding\n",
    "- Correct and justified PCA usage\n",
    "- Strong gradient boosting modeling\n",
    "- Cross-validation and tuning\n",
    "- Interpretable ML pipeline\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
